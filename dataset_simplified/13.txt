multimodal input: IMAGE (640wx427h)

Q="Is the person to the right of the other person staring or sleeping?"

<End of Context>

CAP0=CAP(image=IMAGE)
<result>
The image shows a skateboarder performing a trick at a skate park. The skatepark has a concrete ramp with graffiti on it, and there are trees in the background. The sky is blue and the weather appears to be sunny and clear.
</result>
X=RETRIEVE(question=Q, caption=CAP0)
<result>
a skateboarder
</result>
BOX0=LOC(image=IMAGE,object='person')
<result>
[[178, 153, 322, 297], [143, 96, 158, 129], [149, 144, 178, 180], [5, 116, 83, 141]]
</result>
BOX1=EVAL(expr='max({BOX0}, key=lambda box: box[0] + box[2])')
<result>
[[178, 153, 322, 297]]
</result>
IMAGE0=CROP(image=IMAGE,box=BOX1,index=0)
<result>
The image shows a young man riding a skateboard down the side of a concrete ramp. He is wearing a black helmet, a gray t-shirt, and knee pads. The sky is blue and the weather appears to be sunny.
</result>
ANSWER0=VQA(image=IMAGE0,question='Is the person staring or sleeping?')
<result>
no
</result>
ANSWER1=VQA(image=IMAGE0,question='What is the man doing? Sleeping or staring?')
<result>
watching
</result>
ANSWER2=RESULT(var='The person is staring.')

<End of Plan>