multimodal input: IMAGE (640wx453h)

Q="What is the woman that is standing doing?"

<End of Context>

CAP0=CAP(image=IMAGE)
<result>
The image shows a group of people gathered around an elephant in a park. There are two people sitting on a bench in front of the elephant, one of them is holding a basket and the other is looking at the elephant.
</result>
X=RETRIEVE(question=Q, caption=CAP0)
<result>
a group of people
</result>
BOX0=LOC(image=IMAGE,object='woman')
<result>
[[524, 157, 639, 326], [203, 231, 235, 299], [466, 144, 527, 293]]
</result>
IMAGE0=CROP(image=IMAGE,box=BOX0,index=0)
<result>
The image shows a group of people gathered under a red canopy. The woman on the left is wearing a green t-shirt and is sitting on a wooden bench, while the woman in the middle is standing and holding a basket.
</result>
ANSWER0=RESULT(var='The woman is holding a basket.')

<End of Plan>